{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e92cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pdfquery import PDFQuery\n",
    "import fitz\n",
    "import pdfplumber \n",
    "import re\n",
    "import nltk\n",
    "import cv2 #opencv-python\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "615b80f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://enboyd94:****@nexus.statsperform.tools/repository/public-python/simple\n",
      "Collecting opencv-python\n",
      "  Downloading https://nexus.statsperform.tools/repository/public-python/packages/opencv-python/4.10.0.84/opencv_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /Users/evanboyd/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3dfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'data/Academic_Papers/attention.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49dd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PDFQuery(pdf_path)\n",
    "pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6023c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>, <LTTextLineHorizontal>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_elements = pdf.pq('LTTextLineHorizontal')\n",
    "text_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc92ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [t.text for t in text_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de6f4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'Ashish Vaswani∗ ',\n",
       " 'Google Brain ',\n",
       " 'avaswani@google.com ',\n",
       " 'Noam Shazeer∗ ',\n",
       " 'Google Brain ',\n",
       " 'noam@google.com ',\n",
       " 'Niki Parmar∗ ',\n",
       " 'Google Research ',\n",
       " 'nikip@google.com ',\n",
       " 'Jakob Uszkoreit∗ ',\n",
       " 'Google Research ',\n",
       " 'usz@google.com ',\n",
       " 'Llion Jones∗ ',\n",
       " 'Google Research ',\n",
       " 'llion@google.com ',\n",
       " 'Aidan N. Gomez∗ † ',\n",
       " 'University of Toronto ',\n",
       " 'aidan@cs.toronto.edu ',\n",
       " 'Łukasz Kaiser∗ ',\n",
       " 'Google Brain ',\n",
       " 'lukaszkaiser@google.com ',\n",
       " 'Illia Polosukhin∗ ‡ ',\n",
       " 'illia.polosukhin@gmail.com ',\n",
       " '',\n",
       " 'The dominant sequence transduction models are based on complex recurrent or ',\n",
       " 'convolutional neural networks that include an encoder and a decoder. The best ',\n",
       " 'performing models also connect the encoder and decoder through an attention ',\n",
       " 'mechanism. We propose a new simple network architecture, the Transformer, ',\n",
       " 'based solely on attention mechanisms, dispensing with recurrence and convolutions ',\n",
       " 'entirely. Experiments on two machine translation tasks show these models to ',\n",
       " 'be superior in quality while being more parallelizable and requiring signiﬁcantly ',\n",
       " 'less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- ',\n",
       " 'to-German translation task, improving over the existing best results, including ',\n",
       " 'ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, ',\n",
       " 'our model establishes a new single-model state-of-the-art BLEU score of 41.8 after ',\n",
       " 'training for 3.5 days on eight GPUs, a small fraction of the training costs of the ',\n",
       " 'best models from the literature. We show that the Transformer generalizes well to ',\n",
       " 'other tasks by applying it successfully to English constituency parsing both with ',\n",
       " 'large and limited training data. ',\n",
       " '',\n",
       " '',\n",
       " 'Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks ',\n",
       " 'in particular, have been ﬁrmly established as state of the art approaches in sequence modeling and ',\n",
       " '∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started ',\n",
       " 'the effort to evaluate this idea. Ashish, with Illia, designed and implemented the ﬁrst Transformer models and ',\n",
       " 'has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head ',\n",
       " 'attention and the parameter-free position representation and became the other person involved in nearly every ',\n",
       " 'detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and ',\n",
       " 'tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and ',\n",
       " 'efﬁcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and ',\n",
       " 'implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating ',\n",
       " 'our research. ',\n",
       " '†Work performed while at Google Brain. ',\n",
       " '‡Work performed while at Google Research. ',\n",
       " '',\n",
       " 'transduction problems such as language modeling and machine translation [35, 2, 5]. Numerous ',\n",
       " 'efforts have since continued to push the boundaries of recurrent language models and encoder-decoder ',\n",
       " 'architectures [38, 24, 15]. ',\n",
       " 'Recurrent models typically factor computation along the symbol positions of the input and output ',\n",
       " 'sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden ',\n",
       " 'states ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently ',\n",
       " 'sequential nature precludes parallelization within training examples, which becomes critical at longer ',\n",
       " 'sequence lengths, as memory constraints limit batching across examples. Recent work has achieved ',\n",
       " 'signiﬁcant improvements in computational efﬁciency through factorization tricks [21] and conditional ',\n",
       " 'computation [32], while also improving model performance in case of the latter. The fundamental ',\n",
       " 'constraint of sequential computation, however, remains. ',\n",
       " 'Attention mechanisms have become an integral part of compelling sequence modeling and transduc- ',\n",
       " 'tion models in various tasks, allowing modeling of dependencies without regard to their distance in ',\n",
       " 'the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms ',\n",
       " 'are used in conjunction with a recurrent network. ',\n",
       " 'In this work we propose the Transformer, a model architecture eschewing recurrence and instead ',\n",
       " 'relying entirely on an attention mechanism to draw global dependencies between input and output. ',\n",
       " 'The Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in ',\n",
       " 'translation quality after being trained for as little as twelve hours on eight P100 GPUs. ',\n",
       " '',\n",
       " 'The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU ',\n",
       " '[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building ',\n",
       " 'block, computing hidden representations in parallel for all input and output positions. In these models, ',\n",
       " 'the number of operations required to relate signals from two arbitrary input or output positions grows ',\n",
       " 'in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes ',\n",
       " 'it more difﬁcult to learn dependencies between distant positions [12]. In the Transformer this is ',\n",
       " 'reduced to a constant number of operations, albeit at the cost of reduced effective resolution due ',\n",
       " 'to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as ',\n",
       " 'described in section 3.2. ',\n",
       " 'Self-attention, sometimes called intra-attention is an attention mechanism relating different positions ',\n",
       " 'of a single sequence in order to compute a representation of the sequence. Self-attention has been ',\n",
       " 'used successfully in a variety of tasks including reading comprehension, abstractive summarization, ',\n",
       " 'textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. ',\n",
       " 'End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- ',\n",
       " 'aligned recurrence and have been shown to perform well on simple-language question answering and ',\n",
       " 'language modeling tasks [34]. ',\n",
       " 'To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying ',\n",
       " 'entirely on self-attention to compute representations of its input and output without using sequence- ',\n",
       " 'aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate ',\n",
       " 'self-attention and discuss its advantages over models such as [17, 18] and [9]. ',\n",
       " '',\n",
       " 'Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. ',\n",
       " 'Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence ',\n",
       " 'of continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output ',\n",
       " 'sequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive ',\n",
       " '[10], consuming the previously generated symbols as additional input when generating the next. ',\n",
       " 'The Transformer follows this overall architecture using stacked self-attention and point-wise, fully ',\n",
       " 'connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, ',\n",
       " 'respectively. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two ',\n",
       " 'sub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position- ',\n",
       " 'wise fully connected feed-forward network. We employ a residual connection [11] around each of ',\n",
       " 'the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is ',\n",
       " 'LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer ',\n",
       " 'itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding ',\n",
       " 'layers, produce outputs of dimension dmodel = 512. ',\n",
       " 'Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two ',\n",
       " 'sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head ',\n",
       " 'attention over the output of the encoder stack. Similar to the encoder, we employ residual connections ',\n",
       " 'around each of the sub-layers, followed by layer normalization. We also modify the self-attention ',\n",
       " 'sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This ',\n",
       " 'masking, combined with fact that the output embeddings are offset by one position, ensures that the ',\n",
       " 'predictions for position i can depend only on the known outputs at positions less than i. ',\n",
       " '',\n",
       " 'An attention function can be described as mapping a query and a set of key-value pairs to an output, ',\n",
       " 'where the query, keys, values, and output are all vectors. The output is computed as a weighted sum ',\n",
       " 'of the values, where the weight assigned to each value is computed by a compatibility function of the ',\n",
       " 'query with the corresponding key. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several ',\n",
       " 'attention layers running in parallel. ',\n",
       " '',\n",
       " 'We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of ',\n",
       " 'queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the ',\n",
       " 'dk, and apply a softmax function to obtain the weights on the ',\n",
       " 'query with all keys, divide each by ',\n",
       " 'values. ',\n",
       " '',\n",
       " 'In practice, we compute the attention function on a set of queries simultaneously, packed together ',\n",
       " 'into a matrix Q. The keys and values are also packed together into matrices K and V . We compute ',\n",
       " 'the matrix of outputs as: ',\n",
       " '',\n",
       " 'QK T ',\n",
       " '√ ',\n",
       " 'dk ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'The two most commonly used attention functions are additive attention [2], and dot-product (multi- ',\n",
       " 'plicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor ',\n",
       " 'of ',\n",
       " '. Additive attention computes the compatibility function using a feed-forward network with ',\n",
       " 'a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is ',\n",
       " 'much faster and more space-efﬁcient in practice, since it can be implemented using highly optimized ',\n",
       " 'matrix multiplication code. ',\n",
       " '',\n",
       " 'While for small values of dk the two mechanisms perform similarly, additive attention outperforms ',\n",
       " 'dot product attention without scaling for larger values of dk [3]. We suspect that for large values of ',\n",
       " 'dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has ',\n",
       " 'extremely small gradients 4. To counteract this effect, we scale the dot products by 1√ ',\n",
       " 'dk ',\n",
       " '',\n",
       " '',\n",
       " 'Instead of performing a single attention function with dmodel-dimensional keys, values and queries, ',\n",
       " 'we found it beneﬁcial to linearly project the queries, keys and values h times with different, learned ',\n",
       " 'linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of ',\n",
       " 'queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional ',\n",
       " 'output values. These are concatenated and once again projected, resulting in the ﬁnal values, as ',\n",
       " 'depicted in Figure 2. ',\n",
       " '4To illustrate why the dot products get large, assume that the components of q and k are independent random ',\n",
       " 'i=1 qiki, has mean 0 and variance dk. ',\n",
       " '',\n",
       " '',\n",
       " 'Multi-head attention allows the model to jointly attend to information from different representation ',\n",
       " 'subspaces at different positions. With a single attention head, averaging inhibits this. ',\n",
       " '',\n",
       " '',\n",
       " 'i , KW K ',\n",
       " 'i ',\n",
       " '',\n",
       " '',\n",
       " 'Where the projections are parameter matrices W Q ',\n",
       " 'and W O ∈ Rhdv×dmodel. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'In this work we employ h = 8 parallel attention layers, or heads. For each of these we use ',\n",
       " 'dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost ',\n",
       " 'is similar to that of single-head attention with full dimensionality. ',\n",
       " '',\n",
       " '',\n",
       " '• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, ',\n",
       " 'and the memory keys and values come from the output of the encoder. This allows every ',\n",
       " 'position in the decoder to attend over all positions in the input sequence. This mimics the ',\n",
       " 'typical encoder-decoder attention mechanisms in sequence-to-sequence models such as ',\n",
       " '[38, 2, 9]. ',\n",
       " '• The encoder contains self-attention layers. In a self-attention layer all of the keys, values ',\n",
       " 'and queries come from the same place, in this case, the output of the previous layer in the ',\n",
       " 'encoder. Each position in the encoder can attend to all positions in the previous layer of the ',\n",
       " 'encoder. ',\n",
       " '• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to ',\n",
       " 'all positions in the decoder up to and including that position. We need to prevent leftward ',\n",
       " 'information ﬂow in the decoder to preserve the auto-regressive property. We implement this ',\n",
       " 'inside of scaled dot-product attention by masking out (setting to −∞) all values in the input ',\n",
       " 'of the softmax which correspond to illegal connections. See Figure 2. ',\n",
       " '',\n",
       " 'In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully ',\n",
       " 'connected feed-forward network, which is applied to each position separately and identically. This ',\n",
       " 'consists of two linear transformations with a ReLU activation in between. ',\n",
       " '',\n",
       " '',\n",
       " 'While the linear transformations are the same across different positions, they use different parameters ',\n",
       " 'from layer to layer. Another way of describing this is as two convolutions with kernel size 1. ',\n",
       " 'The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality ',\n",
       " 'df f = 2048. ',\n",
       " '',\n",
       " 'Similarly to other sequence transduction models, we use learned embeddings to convert the input ',\n",
       " 'tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor- ',\n",
       " 'mation and softmax function to convert the decoder output to predicted next-token probabilities. In ',\n",
       " 'our model, we share the same weight matrix between the two embedding layers and the pre-softmax ',\n",
       " 'dmodel. ',\n",
       " 'linear transformation, similar to [30]. In the embedding layers, we multiply those weights by ',\n",
       " '',\n",
       " '',\n",
       " 'Since our model contains no recurrence and no convolution, in order for the model to make use of the ',\n",
       " 'order of the sequence, we must inject some information about the relative or absolute position of the ',\n",
       " '',\n",
       " 'Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations ',\n",
       " 'for different layer types. n is the sequence length, d is the representation dimension, k is the kernel ',\n",
       " 'size of convolutions and r the size of the neighborhood in restricted self-attention. ',\n",
       " '',\n",
       " '',\n",
       " 'Self-Attention ',\n",
       " 'Recurrent ',\n",
       " 'Convolutional ',\n",
       " 'Self-Attention (restricted) ',\n",
       " 'O(n2 · d) ',\n",
       " 'O(n · d2) ',\n",
       " 'O(k · n · d2) ',\n",
       " 'O(r · n · d) ',\n",
       " 'Sequential Maximum Path Length ',\n",
       " 'Operations ',\n",
       " 'O(1) ',\n",
       " 'O(n) ',\n",
       " 'O(1) ',\n",
       " 'O(1) ',\n",
       " 'O(1) ',\n",
       " 'O(n) ',\n",
       " 'O(logk(n)) ',\n",
       " 'O(n/r) ',\n",
       " 'tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the ',\n",
       " 'bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel ',\n",
       " 'as the embeddings, so that the two can be summed. There are many choices of positional encodings, ',\n",
       " 'learned and ﬁxed [9]. ',\n",
       " '',\n",
       " 'P E(pos,2i) = sin(pos/100002i/dmodel) ',\n",
       " 'P E(pos,2i+1) = cos(pos/100002i/dmodel) ',\n",
       " 'where pos is the position and i is the dimension. That is, each dimension of the positional encoding ',\n",
       " 'corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We ',\n",
       " 'chose this function because we hypothesized it would allow the model to easily learn to attend by ',\n",
       " 'relative positions, since for any ﬁxed offset k, P Epos+k can be represented as a linear function of ',\n",
       " 'P Epos. ',\n",
       " 'We also experimented with using learned positional embeddings [9] instead, and found that the two ',\n",
       " 'versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version ',\n",
       " 'because it may allow the model to extrapolate to sequence lengths longer than the ones encountered ',\n",
       " 'during training. ',\n",
       " '',\n",
       " 'In this section we compare various aspects of self-attention layers to the recurrent and convolu- ',\n",
       " 'tional layers commonly used for mapping one variable-length sequence of symbol representations ',\n",
       " '(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden ',\n",
       " 'layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we ',\n",
       " 'consider three desiderata. ',\n",
       " 'One is the total computational complexity per layer. Another is the amount of computation that can ',\n",
       " 'be parallelized, as measured by the minimum number of sequential operations required. ',\n",
       " 'The third is the path length between long-range dependencies in the network. Learning long-range ',\n",
       " 'dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the ',\n",
       " 'ability to learn such dependencies is the length of the paths forward and backward signals have to ',\n",
       " 'traverse in the network. The shorter these paths between any combination of positions in the input ',\n",
       " 'and output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare ',\n",
       " 'the maximum path length between any two input and output positions in networks composed of the ',\n",
       " 'different layer types. ',\n",
       " 'As noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially ',\n",
       " 'executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of ',\n",
       " 'computational complexity, self-attention layers are faster than recurrent layers when the sequence ',\n",
       " 'length n is smaller than the representation dimensionality d, which is most often the case with ',\n",
       " 'sentence representations used by state-of-the-art models in machine translations, such as word-piece ',\n",
       " '[38] and byte-pair [31] representations. To improve computational performance for tasks involving ',\n",
       " 'very long sequences, self-attention could be restricted to considering only a neighborhood of size r in ',\n",
       " '',\n",
       " 'the input sequence centered around the respective output position. This would increase the maximum ',\n",
       " 'path length to O(n/r). We plan to investigate this approach further in future work. ',\n",
       " 'A single convolutional layer with kernel width k < n does not connect all pairs of input and output ',\n",
       " 'positions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels, ',\n",
       " 'or O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths ',\n",
       " 'between any two positions in the network. Convolutional layers are generally more expensive than ',\n",
       " 'recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity ',\n",
       " 'considerably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable ',\n",
       " 'convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer, ',\n",
       " 'the approach we take in our model. ',\n",
       " 'As side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions ',\n",
       " 'from our models and present and discuss examples in the appendix. Not only do individual attention ',\n",
       " 'heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic ',\n",
       " 'and semantic structure of the sentences. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million ',\n",
       " 'sentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source- ',\n",
       " 'target vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT ',\n",
       " '2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece ',\n",
       " 'vocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training ',\n",
       " 'batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 ',\n",
       " 'target tokens. ',\n",
       " '',\n",
       " 'We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using ',\n",
       " 'the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We ',\n",
       " 'trained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the ',\n",
       " 'bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps ',\n",
       " '(3.5 days). ',\n",
       " '',\n",
       " 'We used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and (cid:15) = 10−9. We varied the learning ',\n",
       " 'rate over the course of training, according to the formula: ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'This corresponds to increasing the learning rate linearly for the ﬁrst warmup_steps training steps, ',\n",
       " 'and decreasing it thereafter proportionally to the inverse square root of the step number. We used ',\n",
       " 'warmup_steps = 4000. ',\n",
       " '',\n",
       " '',\n",
       " 'Residual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the ',\n",
       " 'sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the ',\n",
       " 'positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of ',\n",
       " 'Pdrop = 0.1. ',\n",
       " '',\n",
       " 'Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the ',\n",
       " 'English-to-German and English-to-French newstest2014 tests at a fraction of the training cost. ',\n",
       " '',\n",
       " 'ByteNet [18] ',\n",
       " 'Deep-Att + PosUnk [39] ',\n",
       " 'GNMT + RL [38] ',\n",
       " 'ConvS2S [9] ',\n",
       " 'MoE [32] ',\n",
       " 'Deep-Att + PosUnk Ensemble [39] ',\n",
       " 'GNMT + RL Ensemble [38] ',\n",
       " 'ConvS2S Ensemble [9] ',\n",
       " 'Transformer (base model) ',\n",
       " 'Transformer (big) ',\n",
       " '',\n",
       " '',\n",
       " 'EN-DE EN-FR ',\n",
       " '23.75 ',\n",
       " '24.6 ',\n",
       " '25.16 ',\n",
       " '26.03 ',\n",
       " '26.30 ',\n",
       " '26.36 ',\n",
       " '27.3 ',\n",
       " '28.4 ',\n",
       " '39.2 ',\n",
       " '39.92 ',\n",
       " '40.46 ',\n",
       " '40.56 ',\n",
       " '40.4 ',\n",
       " '41.16 ',\n",
       " '41.29 ',\n",
       " '38.1 ',\n",
       " '41.8 ',\n",
       " '',\n",
       " '',\n",
       " '2.3 · 1019 ',\n",
       " '9.6 · 1018 ',\n",
       " '2.0 · 1019 ',\n",
       " '1.8 · 1020 ',\n",
       " '7.7 · 1019 ',\n",
       " '1.0 · 1020 ',\n",
       " '1.4 · 1020 ',\n",
       " '1.5 · 1020 ',\n",
       " '1.2 · 1020 ',\n",
       " '8.0 · 1020 ',\n",
       " '1.1 · 1021 ',\n",
       " '1.2 · 1021 ',\n",
       " '3.3 · 1018 ',\n",
       " '2.3 · 1019 ',\n",
       " 'Label Smoothing During training, we employed label smoothing of value (cid:15)ls = 0.1 [36]. This ',\n",
       " 'hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score. ',\n",
       " '',\n",
       " '',\n",
       " 'On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big) ',\n",
       " 'in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0 ',\n",
       " 'BLEU, establishing a new state-of-the-art BLEU score of 28.4. The conﬁguration of this model is ',\n",
       " 'listed in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model ',\n",
       " 'surpasses all previously published models and ensembles, at a fraction of the training cost of any of ',\n",
       " 'the competitive models. ',\n",
       " 'On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, ',\n",
       " 'outperforming all of the previously published single models, at less than 1/4 the training cost of the ',\n",
       " 'previous state-of-the-art model. The Transformer (big) model trained for English-to-French used ',\n",
       " 'dropout rate Pdrop = 0.1, instead of 0.3. ',\n",
       " 'For the base models, we used a single model obtained by averaging the last 5 checkpoints, which ',\n",
       " 'were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We ',\n",
       " 'used beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters ',\n",
       " 'were chosen after experimentation on the development set. We set the maximum output length during ',\n",
       " 'inference to input length + 50, but terminate early when possible [38]. ',\n",
       " 'Table 2 summarizes our results and compares our translation quality and training costs to other model ',\n",
       " 'architectures from the literature. We estimate the number of ﬂoating point operations used to train a ',\n",
       " 'model by multiplying the training time, the number of GPUs used, and an estimate of the sustained ',\n",
       " 'single-precision ﬂoating-point capacity of each GPU 5. ',\n",
       " '',\n",
       " 'To evaluate the importance of different components of the Transformer, we varied our base model ',\n",
       " 'in different ways, measuring the change in performance on English-to-German translation on the ',\n",
       " 'development set, newstest2013. We used beam search as described in the previous section, but no ',\n",
       " 'checkpoint averaging. We present these results in Table 3. ',\n",
       " 'In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, ',\n",
       " 'keeping the amount of computation constant, as described in Section 3.2.2. While single-head ',\n",
       " 'attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads. ',\n",
       " '',\n",
       " '',\n",
       " 'Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base ',\n",
       " 'model. All metrics are on the English-to-German translation development set, newstest2013. Listed ',\n",
       " 'perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to ',\n",
       " 'per-word perplexities. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '64 ',\n",
       " '512 ',\n",
       " '128 ',\n",
       " '32 ',\n",
       " '16 ',\n",
       " '',\n",
       " '8 ',\n",
       " '1 ',\n",
       " '4 ',\n",
       " '16 ',\n",
       " '32 ',\n",
       " '',\n",
       " '64 ',\n",
       " '512 ',\n",
       " '128 ',\n",
       " '32 ',\n",
       " '16 ',\n",
       " '16 ',\n",
       " '32 ',\n",
       " '2 ',\n",
       " '4 ',\n",
       " '8 ',\n",
       " '256 ',\n",
       " '1024 ',\n",
       " '32 ',\n",
       " '128 ',\n",
       " '32 ',\n",
       " '128 ',\n",
       " '1024 ',\n",
       " '4096 ',\n",
       " '0.0 ',\n",
       " '0.2 ',\n",
       " '0.0 ',\n",
       " '0.2 ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '(E) ',\n",
       " 'big ',\n",
       " 'PPL ',\n",
       " 'train ',\n",
       " 'steps ',\n",
       " '(dev) ',\n",
       " '100K 4.92 ',\n",
       " '5.29 ',\n",
       " '5.00 ',\n",
       " '4.91 ',\n",
       " '5.01 ',\n",
       " '5.16 ',\n",
       " '5.01 ',\n",
       " '6.11 ',\n",
       " '5.19 ',\n",
       " '4.88 ',\n",
       " '5.75 ',\n",
       " '4.66 ',\n",
       " '5.12 ',\n",
       " '4.75 ',\n",
       " '5.77 ',\n",
       " '4.95 ',\n",
       " '4.67 ',\n",
       " '5.47 ',\n",
       " '4.92 ',\n",
       " '300K 4.33 ',\n",
       " 'BLEU params ',\n",
       " '×106 ',\n",
       " '(dev) ',\n",
       " '25.8 ',\n",
       " '65 ',\n",
       " '24.9 ',\n",
       " '25.5 ',\n",
       " '25.8 ',\n",
       " '25.4 ',\n",
       " '25.1 ',\n",
       " '25.4 ',\n",
       " '23.7 ',\n",
       " '25.3 ',\n",
       " '25.5 ',\n",
       " '24.5 ',\n",
       " '26.0 ',\n",
       " '25.4 ',\n",
       " '26.2 ',\n",
       " '24.6 ',\n",
       " '25.5 ',\n",
       " '25.3 ',\n",
       " '25.7 ',\n",
       " '25.7 ',\n",
       " '26.4 ',\n",
       " '58 ',\n",
       " '60 ',\n",
       " '36 ',\n",
       " '50 ',\n",
       " '80 ',\n",
       " '28 ',\n",
       " '168 ',\n",
       " '53 ',\n",
       " '90 ',\n",
       " '',\n",
       " 'Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23 ',\n",
       " 'of WSJ) ',\n",
       " '',\n",
       " '',\n",
       " 'Vinyals & Kaiser el al. (2014) [37] WSJ only, discriminative ',\n",
       " 'WSJ only, discriminative ',\n",
       " 'WSJ only, discriminative ',\n",
       " 'WSJ only, discriminative ',\n",
       " 'WSJ only, discriminative ',\n",
       " 'semi-supervised ',\n",
       " 'semi-supervised ',\n",
       " 'semi-supervised ',\n",
       " 'semi-supervised ',\n",
       " 'semi-supervised ',\n",
       " 'multi-task ',\n",
       " 'generative ',\n",
       " 'Petrov et al. (2006) [29] ',\n",
       " 'Zhu et al. (2013) [40] ',\n",
       " 'Dyer et al. (2016) [8] ',\n",
       " 'Transformer (4 layers) ',\n",
       " 'Zhu et al. (2013) [40] ',\n",
       " 'Huang & Harper (2009) [14] ',\n",
       " 'McClosky et al. (2006) [26] ',\n",
       " 'Vinyals & Kaiser el al. (2014) [37] ',\n",
       " 'Transformer (4 layers) ',\n",
       " 'Luong et al. (2015) [23] ',\n",
       " 'Dyer et al. (2016) [8] ',\n",
       " 'WSJ 23 F1 ',\n",
       " '88.3 ',\n",
       " '90.4 ',\n",
       " '90.4 ',\n",
       " '91.7 ',\n",
       " '91.3 ',\n",
       " '91.3 ',\n",
       " '91.3 ',\n",
       " '92.1 ',\n",
       " '92.1 ',\n",
       " '92.7 ',\n",
       " '93.0 ',\n",
       " '93.3 ',\n",
       " 'In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This ',\n",
       " 'suggests that determining compatibility is not easy and that a more sophisticated compatibility ',\n",
       " 'function than dot product may be beneﬁcial. We further observe in rows (C) and (D) that, as expected, ',\n",
       " 'bigger models are better, and dropout is very helpful in avoiding over-ﬁtting. In row (E) we replace our ',\n",
       " 'sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical ',\n",
       " 'results to the base model. ',\n",
       " '',\n",
       " 'To evaluate if the Transformer can generalize to other tasks we performed experiments on English ',\n",
       " 'constituency parsing. This task presents speciﬁc challenges: the output is subject to strong structural ',\n",
       " '',\n",
       " 'constraints and is signiﬁcantly longer than the input. Furthermore, RNN sequence-to-sequence ',\n",
       " 'models have not been able to attain state-of-the-art results in small-data regimes [37]. ',\n",
       " 'We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the ',\n",
       " 'Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting, ',\n",
       " 'using the larger high-conﬁdence and BerkleyParser corpora from with approximately 17M sentences ',\n",
       " '[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens ',\n",
       " 'for the semi-supervised setting. ',\n",
       " 'We performed only a small number of experiments to select the dropout, both attention and residual ',\n",
       " '(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters ',\n",
       " 'remained unchanged from the English-to-German base translation model. During inference, we ',\n",
       " 'increased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3 ',\n",
       " 'for both WSJ only and the semi-supervised setting. ',\n",
       " 'Our results in Table 4 show that despite the lack of task-speciﬁc tuning our model performs sur- ',\n",
       " 'prisingly well, yielding better results than all previously reported models with the exception of the ',\n",
       " 'Recurrent Neural Network Grammar [8]. ',\n",
       " 'In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley- ',\n",
       " 'Parser [29] even when training only on the WSJ training set of 40K sentences. ',\n",
       " '',\n",
       " 'In this work, we presented the Transformer, the ﬁrst sequence transduction model based entirely on ',\n",
       " 'attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with ',\n",
       " 'multi-headed self-attention. ',\n",
       " 'For translation tasks, the Transformer can be trained signiﬁcantly faster than architectures based ',\n",
       " 'on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 ',\n",
       " 'English-to-French translation tasks, we achieve a new state of the art. In the former task our best ',\n",
       " 'model outperforms even all previously reported ensembles. ',\n",
       " 'We are excited about the future of attention-based models and plan to apply them to other tasks. We ',\n",
       " 'plan to extend the Transformer to problems involving input and output modalities other than text and ',\n",
       " 'to investigate local, restricted attention mechanisms to efﬁciently handle large inputs and outputs ',\n",
       " 'such as images, audio and video. Making generation less sequential is another research goals of ours. ',\n",
       " 'The code we used to train and evaluate our models is available at https://github.com/ ',\n",
       " 'tensorflow/tensor2tensor. ',\n",
       " 'Acknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful ',\n",
       " 'comments, corrections and inspiration. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, ',\n",
       " 'and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical ',\n",
       " 'machine translation. CoRR, abs/1406.1078, 2014. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation ',\n",
       " 'of gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im- ',\n",
       " 'age recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern ',\n",
       " 'Recognition, pages 770–778, 2016. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations ',\n",
       " 'across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural ',\n",
       " 'Language Processing, pages 832–841. ACL, August 2009. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko- ',\n",
       " 'ray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2, ',\n",
       " '2017. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen ',\n",
       " 'Zhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint ',\n",
       " 'arXiv:1703.03130, 2017. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated ',\n",
       " 'corpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993. ',\n",
       " '[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In ',\n",
       " 'Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, ',\n",
       " 'pages 152–159. ACL, June 2006. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact, ',\n",
       " 'and interpretable tree annotation. In Proceedings of the 21st International Conference on ',\n",
       " 'Computational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July ',\n",
       " '2006. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, ',\n",
       " 'and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts ',\n",
       " 'layer. arXiv preprint arXiv:1701.06538, 2017. ',\n",
       " '[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi- ',\n",
       " 'nov. Dropout: a simple way to prevent neural networks from overﬁtting. Journal of Machine ',\n",
       " 'Learning Research, 15(1):1929–1958, 2014. ',\n",
       " '[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory ',\n",
       " 'networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, ',\n",
       " 'Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates, ',\n",
       " 'Inc., 2015. ',\n",
       " '',\n",
       " '',\n",
       " '[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna. ',\n",
       " 'Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015. ',\n",
       " '',\n",
       " '',\n",
       " '[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang ',\n",
       " 'Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine ',\n",
       " 'translation system: Bridging the gap between human and machine translation. arXiv preprint ',\n",
       " 'arXiv:1609.08144, 2016. ',\n",
       " '[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with ',\n",
       " 'fast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016. ',\n",
       " '[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate ',\n",
       " 'shift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume ',\n",
       " '1: Long Papers), pages 434–443. ACL, August 2013. ',\n",
       " '',\n",
       " 'Figure 3: An example of the attention mechanism following long-distance dependencies in the ',\n",
       " 'encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of ',\n",
       " 'the verb ‘making’, completing the phrase ‘making...more difﬁcult’. Attentions here shown only for ',\n",
       " 'the word ‘making’. Different colors represent different heads. Best viewed in color. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: ',\n",
       " 'Full attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5 ',\n",
       " 'and 6. Note that the attentions are very sharp for this word. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'y ',\n",
       " 'n m ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'y ',\n",
       " 'n m ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Figure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the ',\n",
       " 'sentence. We give two such examples above, from two different heads from the encoder self-attention ',\n",
       " 'at layer 5 of 6. The heads clearly learned to perform different tasks. ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'y ',\n",
       " 'n m ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'y ',\n",
       " 'n m ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4313487",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join(map(str, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1483abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(pdf_path, output_folder,file_name):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    i = 1\n",
    "    image_list = []\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"{output_folder}/{file_name}_page_{page_num + 1}_img_{img_index + 1}_figure_{i}.{image_ext}\"\n",
    "            with open(image_filename, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "            #Save image as a variable\n",
    "            img=mpimg.imread(image_filename)\n",
    "            image_list.append(img)\n",
    "            i += 1\n",
    "    pdf_document.close()\n",
    "    return image_list\n",
    "\n",
    "# Example usage\n",
    "images = extract_images(pdf_path, \"data/Academic_Papers/images\", 'attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06d38369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4447303d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88142809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, single_character=True, numbers=True, punctuation=True, lowercase=True, stop_words=True):\n",
    "    # Remove punctuation - do this before tokenizing in case there are dashes that connect words\n",
    "    if punctuation:\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # [word for word in words if word.isalpha()]\n",
    "\n",
    "    words = nltk.tokenize.word_tokenize(text)\n",
    "    stopwrd = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    if lowercase:\n",
    "        words = [word.lower() for word in words]\n",
    "\n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    if single_character:\n",
    "        words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    # Remove numbers\n",
    "    if numbers:\n",
    "        words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    if stop_words:\n",
    "        words = [word for word in words if word not in stopwrd]\n",
    "\n",
    "    # Join words into one string\n",
    "    words = ' '.join(str(e) for e in words)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf4dc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ashish vaswani∗ google brain avaswani @ google.com noam shazeer∗ google brain noam @ google.com niki parmar∗ google research nikip @ google.com jakob uszkoreit∗ google research usz @ google.com llion jones∗ google research llion @ google.com aidan n. gomez∗ † university of toronto aidan @ cs.toronto.edu łukasz kaiser∗ google brain lukaszkaiser @ google.com illia polosukhin∗ ‡ illia.polosukhin @ gmail.com the dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder . the best performing models also connect the encoder and decoder through an attention mechanism . we propose a new simple network architecture , the transformer , based solely on attention mechanisms , dispensing with recurrence and convolutions entirely . experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train . our model achieves 28.4 bleu on the wmt 2014 english- to-german translation task , improving over the existing best results , including ensembles , by over 2 bleu . on the wmt 2014 english-to-french translation task , our model establishes a new single-model state-of-the-art bleu score of 41.8 after training for 3.5 days on eight gpus , a small fraction of the training costs of the best models from the literature . we show that the transformer generalizes well to other tasks by applying it successfully to english constituency parsing both with large and limited training data . recurrent neural networks , long short-term memory [ 13 ] and gated recurrent [ 7 ] neural networks in particular , have been ﬁrmly established as state of the art approaches in sequence modeling and ∗equal contribution . listing order is random . jakob proposed replacing rnns with self-attention and started the effort to evaluate this idea . ashish , with illia , designed and implemented the ﬁrst transformer models and has been crucially involved in every aspect of this work . noam proposed scaled dot-product attention , multi-head attention and the parameter-free position representation and became the other person involved in nearly every detail . niki designed , implemented , tuned and evaluated countless model variants in our original codebase and tensor2tensor . llion also experimented with novel model variants , was responsible for our initial codebase , and efﬁcient inference and visualizations . lukasz and aidan spent countless long days designing various parts of and implementing tensor2tensor , replacing our earlier codebase , greatly improving results and massively accelerating our research . †work performed while at google brain . ‡work performed while at google research . transduction problems such as language modeling and machine translation [ 35 , 2 , 5 ] . numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [ 38 , 24 , 15 ] . recurrent models typically factor computation along the symbol positions of the input and output sequences . aligning the positions to steps in computation time , they generate a sequence of hidden states ht , as a function of the previous hidden state ht−1 and the input for position t. this inherently sequential nature precludes parallelization within training examples , which becomes critical at longer sequence lengths , as memory constraints limit batching across examples . recent work has achieved signiﬁcant improvements in computational efﬁciency through factorization tricks [ 21 ] and conditional computation [ 32 ] , while also improving model performance in case of the latter . the fundamental constraint of sequential computation , however , remains . attention mechanisms have become an integral part of compelling sequence modeling and transduc- tion models in various tasks , allowing modeling of dependencies without regard to their distance in the input or output sequences [ 2 , 19 ] . in all but a few cases [ 27 ] , however , such attention mechanisms are used in conjunction with a recurrent network . in this work we propose the transformer , a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output . the transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight p100 gpus . the goal of reducing sequential computation also forms the foundation of the extended neural gpu [ 16 ] , bytenet [ 18 ] and convs2s [ 9 ] , all of which use convolutional neural networks as basic building block , computing hidden representations in parallel for all input and output positions . in these models , the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions , linearly for convs2s and logarithmically for bytenet . this makes it more difﬁcult to learn dependencies between distant positions [ 12 ] . in the transformer this is reduced to a constant number of operations , albeit at the cost of reduced effective resolution due to averaging attention-weighted positions , an effect we counteract with multi-head attention as described in section 3.2 . self-attention , sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence . self-attention has been used successfully in a variety of tasks including reading comprehension , abstractive summarization , textual entailment and learning task-independent sentence representations [ 4 , 27 , 28 , 22 ] . end-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [ 34 ] . to the best of our knowledge , however , the transformer is the ﬁrst transduction model relying entirely on self-attention to compute representations of its input and output without using sequence- aligned rnns or convolution . in the following sections , we will describe the transformer , motivate self-attention and discuss its advantages over models such as [ 17 , 18 ] and [ 9 ] . most competitive neural sequence transduction models have an encoder-decoder structure [ 5 , 2 , 35 ] . here , the encoder maps an input sequence of symbol representations ( x1 , ... , xn ) to a sequence of continuous representations z = ( z1 , ... , zn ) . given z , the decoder then generates an output sequence ( y1 , ... , ym ) of symbols one element at a time . at each step the model is auto-regressive [ 10 ] , consuming the previously generated symbols as additional input when generating the next . the transformer follows this overall architecture using stacked self-attention and point-wise , fully connected layers for both the encoder and decoder , shown in the left and right halves of figure 1 , respectively . encoder : the encoder is composed of a stack of n = 6 identical layers . each layer has two sub-layers . the ﬁrst is a multi-head self-attention mechanism , and the second is a simple , position- wise fully connected feed-forward network . we employ a residual connection [ 11 ] around each of the two sub-layers , followed by layer normalization [ 1 ] . that is , the output of each sub-layer is layernorm ( x + sublayer ( x ) ) , where sublayer ( x ) is the function implemented by the sub-layer itself . to facilitate these residual connections , all sub-layers in the model , as well as the embedding layers , produce outputs of dimension dmodel = 512 . decoder : the decoder is also composed of a stack of n = 6 identical layers . in addition to the two sub-layers in each encoder layer , the decoder inserts a third sub-layer , which performs multi-head attention over the output of the encoder stack . similar to the encoder , we employ residual connections around each of the sub-layers , followed by layer normalization . we also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions . this masking , combined with fact that the output embeddings are offset by one position , ensures that the predictions for position i can depend only on the known outputs at positions less than i . an attention function can be described as mapping a query and a set of key-value pairs to an output , where the query , keys , values , and output are all vectors . the output is computed as a weighted sum of the values , where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key . figure 2 : ( left ) scaled dot-product attention . ( right ) multi-head attention consists of several attention layers running in parallel . we call our particular attention `` scaled dot-product attention '' ( figure 2 ) . the input consists of queries and keys of dimension dk , and values of dimension dv . we compute the dot products of the dk , and apply a softmax function to obtain the weights on the query with all keys , divide each by values . in practice , we compute the attention function on a set of queries simultaneously , packed together into a matrix q . the keys and values are also packed together into matrices k and v . we compute the matrix of outputs as : qk t √ dk the two most commonly used attention functions are additive attention [ 2 ] , and dot-product ( multi- plicative ) attention . dot-product attention is identical to our algorithm , except for the scaling factor of . additive attention computes the compatibility function using a feed-forward network with a single hidden layer . while the two are similar in theoretical complexity , dot-product attention is much faster and more space-efﬁcient in practice , since it can be implemented using highly optimized matrix multiplication code . while for small values of dk the two mechanisms perform similarly , additive attention outperforms dot product attention without scaling for larger values of dk [ 3 ] . we suspect that for large values of dk , the dot products grow large in magnitude , pushing the softmax function into regions where it has extremely small gradients 4 . to counteract this effect , we scale the dot products by 1√ dk instead of performing a single attention function with dmodel-dimensional keys , values and queries , we found it beneﬁcial to linearly project the queries , keys and values h times with different , learned linear projections to dk , dk and dv dimensions , respectively . on each of these projected versions of queries , keys and values we then perform the attention function in parallel , yielding dv-dimensional output values . these are concatenated and once again projected , resulting in the ﬁnal values , as depicted in figure 2 . 4to illustrate why the dot products get large , assume that the components of q and k are independent random i=1 qiki , has mean 0 and variance dk . multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions . with a single attention head , averaging inhibits this . i , kw k i where the projections are parameter matrices w q and w o ∈ rhdv×dmodel . in this work we employ h = 8 parallel attention layers , or heads . for each of these we use dk = dv = dmodel/h = 64 . due to the reduced dimension of each head , the total computational cost is similar to that of single-head attention with full dimensionality . • in `` encoder-decoder attention '' layers , the queries come from the previous decoder layer , and the memory keys and values come from the output of the encoder . this allows every position in the decoder to attend over all positions in the input sequence . this mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [ 38 , 2 , 9 ] . • the encoder contains self-attention layers . in a self-attention layer all of the keys , values and queries come from the same place , in this case , the output of the previous layer in the encoder . each position in the encoder can attend to all positions in the previous layer of the encoder . • similarly , self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position . we need to prevent leftward information ﬂow in the decoder to preserve the auto-regressive property . we implement this inside of scaled dot-product attention by masking out ( setting to −∞ ) all values in the input of the softmax which correspond to illegal connections . see figure 2 . in addition to attention sub-layers , each of the layers in our encoder and decoder contains a fully connected feed-forward network , which is applied to each position separately and identically . this consists of two linear transformations with a relu activation in between . while the linear transformations are the same across different positions , they use different parameters from layer to layer . another way of describing this is as two convolutions with kernel size 1 . the dimensionality of input and output is dmodel = 512 , and the inner-layer has dimensionality df f = 2048 . similarly to other sequence transduction models , we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel . we also use the usual learned linear transfor- mation and softmax function to convert the decoder output to predicted next-token probabilities . in our model , we share the same weight matrix between the two embedding layers and the pre-softmax dmodel . linear transformation , similar to [ 30 ] . in the embedding layers , we multiply those weights by since our model contains no recurrence and no convolution , in order for the model to make use of the order of the sequence , we must inject some information about the relative or absolute position of the table 1 : maximum path lengths , per-layer complexity and minimum number of sequential operations for different layer types . n is the sequence length , d is the representation dimension , k is the kernel size of convolutions and r the size of the neighborhood in restricted self-attention . self-attention recurrent convolutional self-attention ( restricted ) o ( n2 · d ) o ( n · d2 ) o ( k · n · d2 ) o ( r · n · d ) sequential maximum path length operations o ( 1 ) o ( n ) o ( 1 ) o ( 1 ) o ( 1 ) o ( n ) o ( logk ( n ) ) o ( n/r ) tokens in the sequence . to this end , we add `` positional encodings '' to the input embeddings at the bottoms of the encoder and decoder stacks . the positional encodings have the same dimension dmodel as the embeddings , so that the two can be summed . there are many choices of positional encodings , learned and ﬁxed [ 9 ] . p e ( pos,2i ) = sin ( pos/100002i/dmodel ) p e ( pos,2i+1 ) = cos ( pos/100002i/dmodel ) where pos is the position and i is the dimension . that is , each dimension of the positional encoding corresponds to a sinusoid . the wavelengths form a geometric progression from 2π to 10000 · 2π . we chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions , since for any ﬁxed offset k , p epos+k can be represented as a linear function of p epos . we also experimented with using learned positional embeddings [ 9 ] instead , and found that the two versions produced nearly identical results ( see table 3 row ( e ) ) . we chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training . in this section we compare various aspects of self-attention layers to the recurrent and convolu- tional layers commonly used for mapping one variable-length sequence of symbol representations ( x1 , ... , xn ) to another sequence of equal length ( z1 , ... , zn ) , with xi , zi ∈ rd , such as a hidden layer in a typical sequence transduction encoder or decoder . motivating our use of self-attention we consider three desiderata . one is the total computational complexity per layer . another is the amount of computation that can be parallelized , as measured by the minimum number of sequential operations required . the third is the path length between long-range dependencies in the network . learning long-range dependencies is a key challenge in many sequence transduction tasks . one key factor affecting the ability to learn such dependencies is the length of the paths forward and backward signals have to traverse in the network . the shorter these paths between any combination of positions in the input and output sequences , the easier it is to learn long-range dependencies [ 12 ] . hence we also compare the maximum path length between any two input and output positions in networks composed of the different layer types . as noted in table 1 , a self-attention layer connects all positions with a constant number of sequentially executed operations , whereas a recurrent layer requires o ( n ) sequential operations . in terms of computational complexity , self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d , which is most often the case with sentence representations used by state-of-the-art models in machine translations , such as word-piece [ 38 ] and byte-pair [ 31 ] representations . to improve computational performance for tasks involving very long sequences , self-attention could be restricted to considering only a neighborhood of size r in the input sequence centered around the respective output position . this would increase the maximum path length to o ( n/r ) . we plan to investigate this approach further in future work . a single convolutional layer with kernel width k < n does not connect all pairs of input and output positions . doing so requires a stack of o ( n/k ) convolutional layers in the case of contiguous kernels , or o ( logk ( n ) ) in the case of dilated convolutions [ 18 ] , increasing the length of the longest paths between any two positions in the network . convolutional layers are generally more expensive than recurrent layers , by a factor of k. separable convolutions [ 6 ] , however , decrease the complexity considerably , to o ( k · n · d + n · d2 ) . even with k = n , however , the complexity of a separable convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer , the approach we take in our model . as side beneﬁt , self-attention could yield more interpretable models . we inspect attention distributions from our models and present and discuss examples in the appendix . not only do individual attention heads clearly learn to perform different tasks , many appear to exhibit behavior related to the syntactic and semantic structure of the sentences . we trained on the standard wmt 2014 english-german dataset consisting of about 4.5 million sentence pairs . sentences were encoded using byte-pair encoding [ 3 ] , which has a shared source- target vocabulary of about 37000 tokens . for english-french , we used the signiﬁcantly larger wmt 2014 english-french dataset consisting of 36m sentences and split tokens into a 32000 word-piece vocabulary [ 38 ] . sentence pairs were batched together by approximate sequence length . each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens . we trained our models on one machine with 8 nvidia p100 gpus . for our base models using the hyperparameters described throughout the paper , each training step took about 0.4 seconds . we trained the base models for a total of 100,000 steps or 12 hours . for our big models , ( described on the bottom line of table 3 ) , step time was 1.0 seconds . the big models were trained for 300,000 steps ( 3.5 days ) . we used the adam optimizer [ 20 ] with β1 = 0.9 , β2 = 0.98 and ( cid:15 ) = 10−9 . we varied the learning rate over the course of training , according to the formula : this corresponds to increasing the learning rate linearly for the ﬁrst warmup_steps training steps , and decreasing it thereafter proportionally to the inverse square root of the step number . we used warmup_steps = 4000 . residual dropout we apply dropout [ 33 ] to the output of each sub-layer , before it is added to the sub-layer input and normalized . in addition , we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks . for the base model , we use a rate of pdrop = 0.1 . table 2 : the transformer achieves better bleu scores than previous state-of-the-art models on the english-to-german and english-to-french newstest2014 tests at a fraction of the training cost . bytenet [ 18 ] deep-att + posunk [ 39 ] gnmt + rl [ 38 ] convs2s [ 9 ] moe [ 32 ] deep-att + posunk ensemble [ 39 ] gnmt + rl ensemble [ 38 ] convs2s ensemble [ 9 ] transformer ( base model ) transformer ( big ) en-de en-fr 23.75 24.6 25.16 26.03 26.30 26.36 27.3 28.4 39.2 39.92 40.46 40.56 40.4 41.16 41.29 38.1 41.8 2.3 · 1019 9.6 · 1018 2.0 · 1019 1.8 · 1020 7.7 · 1019 1.0 · 1020 1.4 · 1020 1.5 · 1020 1.2 · 1020 8.0 · 1020 1.1 · 1021 1.2 · 1021 3.3 · 1018 2.3 · 1019 label smoothing during training , we employed label smoothing of value ( cid:15 ) ls = 0.1 [ 36 ] . this hurts perplexity , as the model learns to be more unsure , but improves accuracy and bleu score . on the wmt 2014 english-to-german translation task , the big transformer model ( transformer ( big ) in table 2 ) outperforms the best previously reported models ( including ensembles ) by more than 2.0 bleu , establishing a new state-of-the-art bleu score of 28.4 . the conﬁguration of this model is listed in the bottom line of table 3 . training took 3.5 days on 8 p100 gpus . even our base model surpasses all previously published models and ensembles , at a fraction of the training cost of any of the competitive models . on the wmt 2014 english-to-french translation task , our big model achieves a bleu score of 41.0 , outperforming all of the previously published single models , at less than 1/4 the training cost of the previous state-of-the-art model . the transformer ( big ) model trained for english-to-french used dropout rate pdrop = 0.1 , instead of 0.3 . for the base models , we used a single model obtained by averaging the last 5 checkpoints , which were written at 10-minute intervals . for the big models , we averaged the last 20 checkpoints . we used beam search with a beam size of 4 and length penalty α = 0.6 [ 38 ] . these hyperparameters were chosen after experimentation on the development set . we set the maximum output length during inference to input length + 50 , but terminate early when possible [ 38 ] . table 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature . we estimate the number of ﬂoating point operations used to train a model by multiplying the training time , the number of gpus used , and an estimate of the sustained single-precision ﬂoating-point capacity of each gpu 5 . to evaluate the importance of different components of the transformer , we varied our base model in different ways , measuring the change in performance on english-to-german translation on the development set , newstest2013 . we used beam search as described in the previous section , but no checkpoint averaging . we present these results in table 3 . in table 3 rows ( a ) , we vary the number of attention heads and the attention key and value dimensions , keeping the amount of computation constant , as described in section 3.2.2 . while single-head attention is 0.9 bleu worse than the best setting , quality also drops off with too many heads . table 3 : variations on the transformer architecture . unlisted values are identical to those of the base model . all metrics are on the english-to-german translation development set , newstest2013 . listed perplexities are per-wordpiece , according to our byte-pair encoding , and should not be compared to per-word perplexities . 64 512 128 32 16 8 1 4 16 32 64 512 128 32 16 16 32 2 4 8 256 1024 32 128 32 128 1024 4096 0.0 0.2 0.0 0.2 ( e ) big ppl train steps ( dev ) 100k 4.92 5.29 5.00 4.91 5.01 5.16 5.01 6.11 5.19 4.88 5.75 4.66 5.12 4.75 5.77 4.95 4.67 5.47 4.92 300k 4.33 bleu params ×106 ( dev ) 25.8 65 24.9 25.5 25.8 25.4 25.1 25.4 23.7 25.3 25.5 24.5 26.0 25.4 26.2 24.6 25.5 25.3 25.7 25.7 26.4 58 60 36 50 80 28 168 53 90 table 4 : the transformer generalizes well to english constituency parsing ( results are on section 23 of wsj ) vinyals & kaiser el al . ( 2014 ) [ 37 ] wsj only , discriminative wsj only , discriminative wsj only , discriminative wsj only , discriminative wsj only , discriminative semi-supervised semi-supervised semi-supervised semi-supervised semi-supervised multi-task generative petrov et al . ( 2006 ) [ 29 ] zhu et al . ( 2013 ) [ 40 ] dyer et al . ( 2016 ) [ 8 ] transformer ( 4 layers ) zhu et al . ( 2013 ) [ 40 ] huang & harper ( 2009 ) [ 14 ] mcclosky et al . ( 2006 ) [ 26 ] vinyals & kaiser el al . ( 2014 ) [ 37 ] transformer ( 4 layers ) luong et al . ( 2015 ) [ 23 ] dyer et al . ( 2016 ) [ 8 ] wsj 23 f1 88.3 90.4 90.4 91.7 91.3 91.3 91.3 92.1 92.1 92.7 93.0 93.3 in table 3 rows ( b ) , we observe that reducing the attention key size dk hurts model quality . this suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneﬁcial . we further observe in rows ( c ) and ( d ) that , as expected , bigger models are better , and dropout is very helpful in avoiding over-ﬁtting . in row ( e ) we replace our sinusoidal positional encoding with learned positional embeddings [ 9 ] , and observe nearly identical results to the base model . to evaluate if the transformer can generalize to other tasks we performed experiments on english constituency parsing . this task presents speciﬁc challenges : the output is subject to strong structural constraints and is signiﬁcantly longer than the input . furthermore , rnn sequence-to-sequence models have not been able to attain state-of-the-art results in small-data regimes [ 37 ] . we trained a 4-layer transformer with dmodel = 1024 on the wall street journal ( wsj ) portion of the penn treebank [ 25 ] , about 40k training sentences . we also trained it in a semi-supervised setting , using the larger high-conﬁdence and berkleyparser corpora from with approximately 17m sentences [ 37 ] . we used a vocabulary of 16k tokens for the wsj only setting and a vocabulary of 32k tokens for the semi-supervised setting . we performed only a small number of experiments to select the dropout , both attention and residual ( section 5.4 ) , learning rates and beam size on the section 22 development set , all other parameters remained unchanged from the english-to-german base translation model . during inference , we increased the maximum output length to input length + 300 . we used a beam size of 21 and α = 0.3 for both wsj only and the semi-supervised setting . our results in table 4 show that despite the lack of task-speciﬁc tuning our model performs sur- prisingly well , yielding better results than all previously reported models with the exception of the recurrent neural network grammar [ 8 ] . in contrast to rnn sequence-to-sequence models [ 37 ] , the transformer outperforms the berkeley- parser [ 29 ] even when training only on the wsj training set of 40k sentences . in this work , we presented the transformer , the ﬁrst sequence transduction model based entirely on attention , replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . for translation tasks , the transformer can be trained signiﬁcantly faster than architectures based on recurrent or convolutional layers . on both wmt 2014 english-to-german and wmt 2014 english-to-french translation tasks , we achieve a new state of the art . in the former task our best model outperforms even all previously reported ensembles . we are excited about the future of attention-based models and plan to apply them to other tasks . we plan to extend the transformer to problems involving input and output modalities other than text and to investigate local , restricted attention mechanisms to efﬁciently handle large inputs and outputs such as images , audio and video . making generation less sequential is another research goals of ours . the code we used to train and evaluate our models is available at https : //github.com/ tensorflow/tensor2tensor . acknowledgements we are grateful to nal kalchbrenner and stephan gouws for their fruitful comments , corrections and inspiration . [ 5 ] kyunghyun cho , bart van merrienboer , caglar gulcehre , fethi bougares , holger schwenk , and yoshua bengio . learning phrase representations using rnn encoder-decoder for statistical machine translation . corr , abs/1406.1078 , 2014 . [ 7 ] junyoung chung , çaglar gülçehre , kyunghyun cho , and yoshua bengio . empirical evaluation of gated recurrent neural networks on sequence modeling . corr , abs/1412.3555 , 2014 . [ 11 ] kaiming he , xiangyu zhang , shaoqing ren , and jian sun . deep residual learning for im- age recognition . in proceedings of the ieee conference on computer vision and pattern recognition , pages 770–778 , 2016 . [ 14 ] zhongqiang huang and mary harper . self-training pcfg grammars with latent annotations across languages . in proceedings of the 2009 conference on empirical methods in natural language processing , pages 832–841 . acl , august 2009 . [ 18 ] nal kalchbrenner , lasse espeholt , karen simonyan , aaron van den oord , alex graves , and ko- ray kavukcuoglu . neural machine translation in linear time . arxiv preprint arxiv:1610.10099v2 , 2017 . [ 22 ] zhouhan lin , minwei feng , cicero nogueira dos santos , mo yu , bing xiang , bowen zhou , and yoshua bengio . a structured self-attentive sentence embedding . arxiv preprint arxiv:1703.03130 , 2017 . [ 25 ] mitchell p marcus , mary ann marcinkiewicz , and beatrice santorini . building a large annotated corpus of english : the penn treebank . computational linguistics , 19 ( 2 ) :313–330 , 1993 . [ 26 ] david mcclosky , eugene charniak , and mark johnson . effective self-training for parsing . in proceedings of the human language technology conference of the naacl , main conference , pages 152–159 . acl , june 2006 . [ 29 ] slav petrov , leon barrett , romain thibaux , and dan klein . learning accurate , compact , and interpretable tree annotation . in proceedings of the 21st international conference on computational linguistics and 44th annual meeting of the acl , pages 433–440 . acl , july 2006 . [ 32 ] noam shazeer , azalia mirhoseini , krzysztof maziarz , andy davis , quoc le , geoffrey hinton , and jeff dean . outrageously large neural networks : the sparsely-gated mixture-of-experts layer . arxiv preprint arxiv:1701.06538 , 2017 . [ 33 ] nitish srivastava , geoffrey e hinton , alex krizhevsky , ilya sutskever , and ruslan salakhutdi- nov . dropout : a simple way to prevent neural networks from overﬁtting . journal of machine learning research , 15 ( 1 ) :1929–1958 , 2014 . [ 34 ] sainbayar sukhbaatar , arthur szlam , jason weston , and rob fergus . end-to-end memory networks . in c. cortes , n. d. lawrence , d. d. lee , m. sugiyama , and r. garnett , editors , advances in neural information processing systems 28 , pages 2440–2448 . curran associates , inc. , 2015 . [ 36 ] christian szegedy , vincent vanhoucke , sergey ioffe , jonathon shlens , and zbigniew wojna . rethinking the inception architecture for computer vision . corr , abs/1512.00567 , 2015 . [ 38 ] yonghui wu , mike schuster , zhifeng chen , quoc v le , mohammad norouzi , wolfgang macherey , maxim krikun , yuan cao , qin gao , klaus macherey , et al . google ’ s neural machine translation system : bridging the gap between human and machine translation . arxiv preprint arxiv:1609.08144 , 2016 . [ 39 ] jie zhou , ying cao , xuguang wang , peng li , and wei xu . deep recurrent models with fast-forward connections for neural machine translation . corr , abs/1606.04199 , 2016 . [ 40 ] muhua zhu , yue zhang , wenliang chen , min zhang , and jingbo zhu . fast and accurate shift-reduce constituent parsing . in proceedings of the 51st annual meeting of the acl ( volume 1 : long papers ) , pages 434–443 . acl , august 2013 . figure 3 : an example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6 . many of the attention heads attend to a distant dependency of the verb ‘ making ’ , completing the phrase ‘ making ... more difﬁcult ’ . attentions here shown only for the word ‘ making ’ . different colors represent different heads . best viewed in color . figure 4 : two attention heads , also in layer 5 of 6 , apparently involved in anaphora resolution . top : full attentions for head 5 . bottom : isolated attentions from just the word ‘ its ’ for attention heads 5 and 6 . note that the attentions are very sharp for this word . y n m y n m figure 5 : many of the attention heads exhibit behaviour that seems related to the structure of the sentence . we give two such examples above , from two different heads from the encoder self-attention at layer 5 of 6 . the heads clearly learned to perform different tasks . y n m y n m\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(text, numbers=False,punctuation=False,stop_words=False, single_character=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfcae237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_academic_info(list_of_articles):\n",
    "\n",
    "    academic_tools = []\n",
    "    for name in list_of_articles:\n",
    "\n",
    "        paper_text, paper_images, paper_image_names = get_info_from_pdf(f\"../data/Academic_Papers/{name}.pdf\", \"../data/Academic_Papers/images\",name)\n",
    "        ans = {\"paper_name\": f\"{name}.pdf\",\n",
    "               \"paper_text\": paper_text,\n",
    "               \"paper_image_names\": paper_images,\n",
    "               \"paper_images\": paper_images}\n",
    "        academic_tools.append(ans)\n",
    "    return academic_tools\n",
    "\n",
    "def get_info_from_pdf(pdf_path, write_path, name_of_article):\n",
    "\n",
    "    #Read the PDF query\n",
    "    pdf = PDFQuery(pdf_path)\n",
    "    pdf.load()\n",
    "\n",
    "    #Gather all text elements\n",
    "    text_elements = pdf.pq('LTTextLineHorizontal')\n",
    "    text = [t.text for t in text_elements]\n",
    "\n",
    "    #Clean up a little\n",
    "    text = ''.join(map(str, text))\n",
    "\n",
    "    ##Get images\n",
    "    images, names = extract_images(pdf_path, write_path, name_of_article)\n",
    "\n",
    "    return text, images, names\n",
    "\n",
    "\n",
    "\n",
    "def extract_images(pdf_path, output_folder,file_name):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    i = 1\n",
    "    image_list = []\n",
    "    image_names = []\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        images = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"{output_folder}/{file_name}_page_{page_num + 1}_img_{img_index + 1}_figure_{i}.{image_ext}\"\n",
    "            with open(image_filename, \"wb\") as image_file:\n",
    "                image_file.write(image_bytes)\n",
    "            #Save image as a variable\n",
    "            img=mpimg.imread(image_filename)\n",
    "            image_list.append(img)\n",
    "            image_names.append(image_filename)\n",
    "            i += 1\n",
    "    pdf_document.close()\n",
    "    return image_list, image_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
